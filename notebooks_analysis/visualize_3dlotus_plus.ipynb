{
 "cells": [
  {
   "cell_type": "code",
   "id": "ade1aa6328753ef3",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from moviepy import VideoFileClip\n",
    "from IPython.display import Image, display\n",
    "from plotly.subplots import make_subplots\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import copy\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8075248ff3beae9c",
   "metadata": {},
   "source": [
    "def visualize_pcd_sequence(xyz_list, rgb_list, actions_list, num_cols, pc_labels_list):\n",
    "    num_keysteps = len(xyz_list)\n",
    "    num_rows = (num_keysteps + num_cols - 1) // num_cols\n",
    "\n",
    "    # Create subplot figure\n",
    "    fig = make_subplots(\n",
    "        rows=num_rows, \n",
    "        cols=num_cols,\n",
    "        specs=[[{'type': 'scene'} for _ in range(num_cols)] for _ in range(num_rows)],\n",
    "        subplot_titles=[f'Step {i}' for i in range(num_keysteps)]\n",
    "    )\n",
    "\n",
    "    if len(rgb_list) == 0:\n",
    "        rgb_list = []\n",
    "        for id, xyz in enumerate(xyz_list):\n",
    "            # 0: normal point, light grey\n",
    "            # 1: gripper, blue\n",
    "            # 2: object, orange\n",
    "            # 3: target, green\n",
    "            labels = pc_labels_list[id]\n",
    "            rgb = np.zeros((xyz.shape[0], 3))\n",
    "            \n",
    "            # Set colors based on labels\n",
    "            rgb[labels == 0] = [0.7, 0.7, 0.7]  # Light grey\n",
    "            rgb[labels == 1] = [0.0, 0.0, 1.0]  # Blue\n",
    "            rgb[labels == 2] = [1.0, 0.65, 0.0] # Orange\n",
    "            rgb[labels == 3] = [0.0, 1.0, 0.0]  # Green\n",
    "            \n",
    "            rgb_list.append(rgb)\n",
    "\n",
    "    if actions_list is None:\n",
    "        actions_list = [[] for _ in range(num_keysteps)]\n",
    "\n",
    "    # Plot PCDs and actions for each keystep\n",
    "    for idx, (xyz, rgb, actions) in enumerate(zip(xyz_list, rgb_list, actions_list)):\n",
    "        row = idx // num_cols + 1\n",
    "        col = idx % num_cols + 1\n",
    "        \n",
    "        # Convert RGB values to strings\n",
    "        colors = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b in rgb]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=xyz[:, 0],\n",
    "                y=xyz[:, 1],\n",
    "                z=xyz[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=2,\n",
    "                    color=colors,\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "        for action in actions:\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=[action[0]],\n",
    "                    y=[action[1]],\n",
    "                    z=[action[2]],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=5,\n",
    "                        color='red',\n",
    "                        opacity=1.0\n",
    "                    ),\n",
    "                    name=\"Action\",\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=400 * num_rows,\n",
    "        width=400 * num_cols,\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    scene_settings = dict(\n",
    "        aspectmode='data',\n",
    "        xaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True),\n",
    "        yaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True),\n",
    "        zaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True)\n",
    "    )\n",
    "    \n",
    "    for i in range(1, num_keysteps + 1):\n",
    "        fig.update_scenes(scene_settings, row=((i-1)//num_cols + 1), col=((i-1)%num_cols + 1))\n",
    "\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a9a2e2311567de5",
   "metadata": {},
   "source": [
    "def display_front_view_sequence(obs_dict, col_nb: int = 4):\n",
    "    front_view_sequence = []\n",
    "    for step in range(num_steps):\n",
    "        try:\n",
    "            obs_rgb = obs_dict[step]['obs']['rgb']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        front_view = obs_rgb[-1]\n",
    "        front_view_sequence.append(front_view)\n",
    "    cursor = 0\n",
    "    while cursor < len(front_view_sequence):\n",
    "        plt.imshow(np.concatenate(front_view_sequence[cursor:cursor+col_nb], axis=1))\n",
    "        plt.show()\n",
    "        cursor += col_nb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fdb452bd-3514-45c4-9487-bd188e55bb6c",
   "metadata": {},
   "source": [
    "def load_one_step(step, steps_root_dir):\n",
    "    file = f\"step_{step}.npy\"\n",
    "    print(f\"loading step: {step}\")\n",
    "    step_array = np.load(f\"{steps_root_dir}/{file}\", allow_pickle=True)\n",
    "    return step_array"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "abf50301e988dbd4",
   "metadata": {},
   "source": [
    "from functools import partial\n",
    "\n",
    "def load_steps_data(episode_dir, num_threads=None):\n",
    "    steps_root_dir = f\"{episode_dir}/steps\"\n",
    "\n",
    "    step_files = os.listdir(steps_root_dir)\n",
    "    num_steps = len(step_files)\n",
    "    print(f\"list of steps: {step_files}\")\n",
    "\n",
    "    load_step_partial = partial(load_one_step, steps_root_dir=steps_root_dir)\n",
    "\n",
    "    with ThreadPool(processes=num_threads) as pool:\n",
    "        steps = range(num_steps)\n",
    "        results = pool.map(load_step_partial, steps)\n",
    "\n",
    "    obs_dict = {step: result[()] for step, result in zip(steps, results)}\n",
    "    \n",
    "    return obs_dict, num_steps"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "56ee82d49c5979b",
   "metadata": {},
   "source": [
    "def load_video_data(episode_dir):\n",
    "    video_dir = [folder for folder in os.listdir(episode_dir) if \"video\" in folder][0]\n",
    "    success_rate = video_dir.strip(\"video-SR\")\n",
    "\n",
    "    video_path = os.path.join(episode_dir, video_dir, \"global.avi\")\n",
    "    gif_output_path = \"gif/robot_action.gif\"\n",
    "    \n",
    "    gif_path = convert_video_to_gif(video_path, gif_output_path)\n",
    "    \n",
    "    return success_rate, gif_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e1554a0b04c8968",
   "metadata": {},
   "source": [
    "def prepare_keysteps_pcd_sequence(obs_dict, num_steps):\n",
    "    xyz_list = []\n",
    "    actions_list = []\n",
    "    pc_labels_list = []\n",
    "    plans_list = []\n",
    "    action_name_lists = []\n",
    "    cache_list = []\n",
    "    gripper_pos_list = []\n",
    "    mp_error_list = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        batch = obs_dict[step]['batch']\n",
    "        valid_actions = obs_dict[step]['valid_actions']\n",
    "        \n",
    "        if batch is None:\n",
    "            # nothing changes, except for the action\n",
    "            batch = obs_dict[step-1]['batch']\n",
    "\n",
    "        xyz = batch['pc_fts'][:, :3]\n",
    "        xyz_list.append(xyz)\n",
    "\n",
    "        denormalized_valid_actions = []\n",
    "        valid_action = valid_actions[0]\n",
    "        \n",
    "        pos = (valid_action[:3] - batch['pc_centroids']) / batch['pc_radius']\n",
    "        denormalized_action = np.concatenate([pos, valid_action[3:]])\n",
    "        if len(denormalized_action) == 8: # action is release, and in the code when it happens the action is len(8) instead of 9 which spoils the code\n",
    "            denormalized_action = np.concatenate([denormalized_action, [404]])\n",
    "        denormalized_valid_actions.append(denormalized_action)\n",
    "            \n",
    "        actions_list.append(denormalized_valid_actions)\n",
    "\n",
    "        pc_labels_list.append(batch['pc_labels'])\n",
    "        \n",
    "        if obs_dict[step]['plan'] is not None:\n",
    "            plans_list.append(obs_dict[step]['plan'])\n",
    "        else:\n",
    "            plans_list.append({})\n",
    "            \n",
    "        \n",
    "        if obs_dict[step]['action_name'] is not None:\n",
    "            action_name_lists.append(obs_dict[step]['action_name'])\n",
    "        else:\n",
    "            action_name_lists.append([])\n",
    "        \n",
    "        if obs_dict[step]['cache'] is not None:\n",
    "            cache_list.append(obs_dict[step]['cache'])\n",
    "        else:\n",
    "            cache_list.append({})\n",
    "\n",
    "        gripper_pos = copy.deepcopy(obs_dict[step]['obs'][\"gripper\"])\n",
    "        gripper_pos[:3] = (gripper_pos[:3] - batch['pc_centroids']) / batch['pc_radius']\n",
    "        gripper_pos_list.append(gripper_pos)\n",
    "\n",
    "        if step == 0:\n",
    "            mp_error_list.append((0,gripper_pos[:3],[0,0,0]))\n",
    "        else:\n",
    "            current_gripper_pos = gripper_pos[:3]\n",
    "            previous_gripper_target = (obs_dict[step-1]['valid_actions'][0][:3] - batch['pc_centroids']) / batch['pc_radius']\n",
    "            previous_gripper_target_pos = previous_gripper_target[:3]\n",
    "            mp_error = np.sqrt(sum( (current_gripper_pos[i] - previous_gripper_target_pos[i])**2 for i in range(3)))\n",
    "            mp_error_list.append((round(mp_error,3), current_gripper_pos, previous_gripper_target_pos))\n",
    "    \n",
    "    return xyz_list, actions_list, pc_labels_list, plans_list, action_name_lists, cache_list, gripper_pos_list, mp_error_list"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5132e6b2dc4a1d2d",
   "metadata": {},
   "source": [
    "def display_plan(plans, actions_list):\n",
    "    for step, plan in enumerate(plans):\n",
    "        print(f\"# Step {step}:\")\n",
    "        print(f\"Plan: {plan}\")\n",
    "        print(f\"Action: {actions_list[step]}\")\n",
    "        gripper_states = [f\"{action[7]}, {'Open' if action[7] == 1 else 'Closed'}\" for action in actions_list[step]]\n",
    "        print(f\"Gripper states: {gripper_states}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "970c764522127105",
   "metadata": {},
   "source": [
    "def quaternion_to_rotation_matrix(qx, qy, qz, qw):\n",
    "    R = np.zeros((3, 3))\n",
    "    R[0, 0] = 1 - 2*qy**2 - 2*qz**2\n",
    "    R[0, 1] = 2*qx*qy - 2*qz*qw\n",
    "    R[0, 2] = 2*qx*qz + 2*qy*qw\n",
    "    R[1, 0] = 2*qx*qy + 2*qz*qw\n",
    "    R[1, 1] = 1 - 2*qx**2 - 2*qz**2\n",
    "    R[1, 2] = 2*qy*qz - 2*qx*qw\n",
    "    R[2, 0] = 2*qx*qz - 2*qy*qw\n",
    "    R[2, 1] = 2*qy*qz + 2*qx*qw\n",
    "    R[2, 2] = 1 - 2*qx**2 - 2*qy**2\n",
    "\n",
    "    return R.T\n",
    "\n",
    "def transform_gripper_points(xyz, labels, action, gripper_pos):\n",
    "    \"\"\"Transform gripper points according to predicted action.\"\"\"\n",
    "    # Extract gripper points\n",
    "    gripper_mask = labels == 1\n",
    "    gripper_points = xyz[gripper_mask].copy()\n",
    "    \n",
    "    if len(gripper_points) == 0:\n",
    "        return np.array([])\n",
    "        \n",
    "    # Calculate current centroid of gripper points\n",
    "    current_centroid = gripper_pos[:3]\n",
    "    \n",
    "    # Center points around origin\n",
    "    centered_points = gripper_points - current_centroid\n",
    "    \n",
    "    # Extract target position and rotation from action\n",
    "    target_position = action[:3]\n",
    "    qx, qy, qz, qw = action[3:7]\n",
    "\n",
    "    current_qx, current_qy, current_qz, current_qw = gripper_pos[3:7]\n",
    "    R_current_rot = quaternion_to_rotation_matrix(current_qx, current_qy, current_qz, current_qw)\n",
    "    \n",
    "    # Rotation target\n",
    "    R_target = quaternion_to_rotation_matrix(qx, qy, qz, qw)\n",
    "    \n",
    "    # Apply rotation if needed (combining fix rotation with quaternion rotation)\n",
    "    distance_quaternions_gripper_pos_target_pose = np.sqrt(sum( (action[3:7][i] - gripper_pos[3:7][i])**2 for i in range(4)))\n",
    "    print(f\"distance_quaternions_gripper_pos_target_pose: {distance_quaternions_gripper_pos_target_pose}\")\n",
    "    if distance_quaternions_gripper_pos_target_pose < 0.01:\n",
    "        # If the distance between the quaternions of the current pose and the target pose is almost zero, then no need to rotate the target\n",
    "        rotated_points = centered_points\n",
    "    else:\n",
    "        rotated_points = centered_points @ R_current_rot @ R_target\n",
    "    \n",
    "    # Translate to target position\n",
    "    transformed_points = rotated_points + target_position\n",
    "    \n",
    "    return transformed_points\n",
    "\n",
    "def display_story(start_idx, plans_list, xyz_list, actions_list, pc_labels_list, obs_dict, cache_list, action_name_lists, gripper_pos_list, mp_error_list):\n",
    "    for step, plan in enumerate(plans_list):\n",
    "        step = step + start_idx\n",
    "        print(f\"\\033[1m# Step {step}:\\033[0m\")\n",
    "        print(f\"Plan:\")\n",
    "        print(f\"Action_name: {action_name_lists[step]}\")\n",
    "        for key in plan:\n",
    "            print(f\"\\033[4m{key}\\033[0m: {plan[key]}\")\n",
    "        print(f\"MP error = {mp_error_list[step][0]}\")\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            specs=[[{\"type\": \"image\"}, {\"type\": \"scene\"}]],\n",
    "            subplot_titles=[\"Front View\", \"Point Cloud\"]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            front_view = obs_dict[step]['obs']['rgb'][-1]\n",
    "            fig.add_trace(\n",
    "                go.Image(z=front_view),\n",
    "                row=1, col=1\n",
    "            )\n",
    "        except KeyError:\n",
    "            print(f\"No front view image for step {step}\")\n",
    "\n",
    "        try:\n",
    "            xyz = xyz_list[step]\n",
    "            labels = pc_labels_list[step]\n",
    "            gripper_pos = gripper_pos_list[step]\n",
    "\n",
    "            rgb = np.zeros((xyz.shape[0], 3))\n",
    "            rgb[labels == 0] = [0.7, 0.7, 0.7]  # Light grey\n",
    "            rgb[labels == 1] = [0.0, 0.0, 1.0]  # Blue\n",
    "            rgb[labels == 2] = [1.0, 0.65, 0.0]  # Orange\n",
    "            rgb[labels == 3] = [0.0, 1.0, 0.0]  # Green\n",
    "            colors = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b in rgb]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=xyz[:, 0],\n",
    "                    y=xyz[:, 1],\n",
    "                    z=xyz[:, 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=2,\n",
    "                        color=colors,\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "\n",
    "            for action in actions_list[step]:\n",
    "                # Transform gripper points (\"imagine\" the target pose)\n",
    "                transformed_points = transform_gripper_points(xyz, labels, action, gripper_pos)\n",
    "                gripper_state_current = 1 if gripper_pos[-1] > 0.5 else 0\n",
    "                gripper_state_target = 1 if action[-2] > 0.5 else 0\n",
    "                print(f\"Current Gripper State: {'Open' if gripper_state_current == 1 else 'Closed'}\")\n",
    "                print(f\"Target Gripper State: {'Open' if gripper_state_target == 1 else 'Closed'}\")\n",
    "                print(f'Action: {action}')\n",
    "                print(f'Gripper pos: {gripper_pos}')\n",
    "\n",
    "                # When the gripper changes its state, we want to see it visually, so we use another color\n",
    "                color_target_action = 'red' if gripper_state_current == gripper_state_target else 'yellow'\n",
    "                if plan['action'] == 'release':\n",
    "                    color_target_action = 'yellow'\n",
    "\n",
    "                if len(transformed_points) > 0:\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter3d(\n",
    "                            x=transformed_points[:, 0],\n",
    "                            y=transformed_points[:, 1],\n",
    "                            z=transformed_points[:, 2],\n",
    "                            mode='markers',\n",
    "                            marker=dict(\n",
    "                                size=2,\n",
    "                                color=color_target_action,\n",
    "                                opacity=0.8\n",
    "                            ),\n",
    "                            name=\"Predicted Gripper\",\n",
    "                            showlegend=False\n",
    "                        ),\n",
    "                        row=1, col=2\n",
    "                    )\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter3d(\n",
    "                            x=[action[0]],\n",
    "                            y=[action[1]],\n",
    "                            z=[action[2]],\n",
    "                            mode='markers',\n",
    "                            marker=dict(\n",
    "                                size=6,\n",
    "                                color='pink',\n",
    "                                opacity=0.8\n",
    "                            ),\n",
    "                            name=\"Predicted Gripper Pose\",\n",
    "                            showlegend=False\n",
    "                        ),\n",
    "                        row=1, col=2\n",
    "                    )\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=[gripper_pos[0]],\n",
    "                    y=[gripper_pos[1]],\n",
    "                    z=[gripper_pos[2]],\n",
    "                    mode='markers',\n",
    "                    marker=dict(\n",
    "                        size=4,\n",
    "                        color='green',\n",
    "                        opacity=0.8\n",
    "                    ),\n",
    "                    name=\"Gripper Position\",\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            if step !=0:\n",
    "                print(f\"mp_error_list: {mp_error_list[step]}\")\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter3d(\n",
    "                        x=[mp_error_list[step][2][0]],\n",
    "                        y=[mp_error_list[step][2][1]],\n",
    "                        z=[mp_error_list[step][2][2]],\n",
    "                        mode='markers',\n",
    "                        marker=dict(\n",
    "                            size=6,\n",
    "                            color='purple',\n",
    "                            opacity=0.8\n",
    "                        ),\n",
    "                        name=\"Previous Target Gripper Position\",\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=1, col=2\n",
    "                )\n",
    "        except IndexError:\n",
    "            print(f\"No point cloud data for step {step}\")\n",
    "\n",
    "        fig.update_layout(\n",
    "            height=500,\n",
    "            width=1000,\n",
    "            margin=dict(l=0, r=0, b=0, t=30),\n",
    "            paper_bgcolor='white',\n",
    "            plot_bgcolor='white'\n",
    "        )\n",
    "\n",
    "        scene_settings = dict(\n",
    "            aspectmode='data',\n",
    "            xaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True),\n",
    "            yaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True),\n",
    "            zaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True)\n",
    "        )\n",
    "        fig.update_scenes(scene_settings)\n",
    "\n",
    "        fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ab26c1e1152712f",
   "metadata": {},
   "source": [
    "def convert_video_to_gif(video_path, output_path):\n",
    "    print(f\"Converting video to GIF...\")\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    video_clip.write_gif(output_path, fps=10)\n",
    "\n",
    "    video_clip.close()\n",
    "\n",
    "    gif_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"GIF size: {gif_size_mb:.2f} MB\")\n",
    "\n",
    "    return output_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "71e68a3e86aad6c3",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "benchmark=\"peract\"\n",
    "seed = 200\n",
    "model = \"3dlotusplus/v2_mix\"\n",
    "taskvar = \"put_item_in_drawer_peract+2\"\n",
    "\n",
    "taskvar_records_dir = f\"../data/experiments/{benchmark}/{model}/records/seed{seed}/{taskvar}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b2f6f5cf-d199-4fcc-aba1-fa0e0d1f0de8",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> ------------ Run ------------  </span>"
   ]
  },
  {
   "cell_type": "code",
   "id": "917de863822a0ccc",
   "metadata": {},
   "source": [
    "# list all episodes along with their success rate\n",
    "list_dir = os.listdir(taskvar_records_dir)\n",
    "sorted_list_dir = sorted(list_dir, key=lambda x: int(x.split('_')[1]) if 'ep_' in x else float('inf'))\n",
    "\n",
    "for folder in sorted_list_dir:\n",
    "    if \"ep\" in folder:\n",
    "        episode_id = folder.split('_')[1]\n",
    "        episode_dir = f\"{taskvar_records_dir}/{folder}\"\n",
    "        video_dir = [folder for folder in os.listdir(episode_dir) if \"video\" in folder][0]\n",
    "        success_rate = video_dir.strip(\"video-SR\")\n",
    "        nb_steps = len(os.listdir(f\"{episode_dir}/steps\"))\n",
    "        print(f\"Ep {episode_id}: SR={success_rate}, steps={nb_steps}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bdebe6d7dfe589a7",
   "metadata": {},
   "source": [
    "episode_id = 22"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "863a38b6410bfc14",
   "metadata": {},
   "source": [
    "episode_dir=f\"{taskvar_records_dir}/ep_{episode_id}\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "obs_dict, num_steps = load_steps_data(episode_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "27c1a272e96e553f",
   "metadata": {},
   "source": [
    "success_rate, gif_path = load_video_data(episode_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "742c054993646794",
   "metadata": {},
   "source": [
    "xyz_list, actions_list, pc_labels_list, plans_list, action_name_lists, cache_list, gripper_pos_list, mp_error_list = prepare_keysteps_pcd_sequence(obs_dict, num_steps)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ceaedf44971ac32a",
   "metadata": {},
   "source": [
    "display(Image(filename=gif_path))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "16ade656b7d8f653",
   "metadata": {},
   "source": [
    "highlevel_plans = json.load(open(f\"{episode_dir}/highlevel_plans.json\", \"r\"))\n",
    "\n",
    "print(f\"### {taskvar}, SR: {success_rate}\")\n",
    "print(f\"# Task Planning - LLM\")\n",
    "print(f\"\\033[4m Input \\033[0m: {highlevel_plans['instruction']}\")\n",
    "print(f\"\\033[4m Output \\033[0m:\")\n",
    "for i, plan in enumerate(highlevel_plans['plans']):\n",
    "    print(f\" Step {i}: {plan}\")\n",
    "print(f\"\\033[4m Output parsed \\033[0m:\")\n",
    "for i, plan in enumerate(highlevel_plans['parsed_plans']):\n",
    "    print(f\"Step {i}: {plan}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0c1dc79-b3f1-4d56-85c7-eb5722ed0c9c",
   "metadata": {},
   "source": [
    "subplan1 = [p for i, p in enumerate(plans_list) if i <= len(plans_list)/3]\n",
    "subplan2 = [p for i, p in enumerate(plans_list) if (i <= 2*len(plans_list)/3 and i > len(plans_list)/3)]\n",
    "subplan3 = [p for i, p in enumerate(plans_list) if (i <= len(plans_list) and i > 2*len(plans_list)/3)]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff274688565a4dc",
   "metadata": {},
   "source": [
    "display_story(0, subplan1, xyz_list, actions_list, pc_labels_list, obs_dict, cache_list, action_name_lists, gripper_pos_list, mp_error_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2ee85a9d-a3c0-4b83-b2df-cc1662dfa409",
   "metadata": {},
   "source": [
    "display_story(int(len(plans_list)/3) + 1, subplan2, xyz_list, actions_list, pc_labels_list, obs_dict, cache_list, action_name_lists, gripper_pos_list, mp_error_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ebe7cfb-3ed9-4ddd-9845-003515767795",
   "metadata": {},
   "source": [
    "display_story(int(2*len(plans_list)/3) + 1, subplan3, xyz_list, actions_list, pc_labels_list, obs_dict, cache_list, action_name_lists, gripper_pos_list, mp_error_list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9e8a769c0b0a6e7",
   "metadata": {},
   "source": [
    "from genrobo3d.utils.point_cloud import voxelize_pcd, get_pc_foreground_mask\n",
    "from genrobo3d.utils.robot_box import RobotBox\n",
    "import open3d as o3d\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "class GroundtruthVision(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt_label_file,\n",
    "        num_points=4096,\n",
    "        voxel_size=0.01,\n",
    "        same_npoints_per_example=False,\n",
    "        rm_robot=\"box_keep_gripper\",\n",
    "        xyz_shift=\"center\",\n",
    "        xyz_norm=False,\n",
    "        use_height=True,\n",
    "        pc_label_type=\"coarse\",\n",
    "        use_color=False,\n",
    "    ):\n",
    "        self.taskvar_gt_target_labels = json.load(open(gt_label_file))\n",
    "        self.workspace = {\n",
    "            'TABLE_HEIGHT': 0.7505,\n",
    "            'X_BBOX': (-0.5, 1.5),\n",
    "            'Y_BBOX': (-1, 1),\n",
    "            'Z_BBOX': (0.2, 2)\n",
    "        }\n",
    "        self.TABLE_HEIGHT = self.workspace[\"TABLE_HEIGHT\"]\n",
    "\n",
    "        self.num_points = num_points\n",
    "        self.voxel_size = voxel_size\n",
    "        self.pc_label_type = pc_label_type\n",
    "        self.same_npoints_per_example = same_npoints_per_example\n",
    "        self.rm_robot = rm_robot\n",
    "        self.xyz_shift = xyz_shift\n",
    "        self.xyz_norm = xyz_norm\n",
    "        self.use_height = use_height\n",
    "        self.use_color = use_color\n",
    "\n",
    "    def get_target_labels(self, taskvar, step_id, episode):\n",
    "        \"\"\"\n",
    "        Flexibly access target labels handling both direct step_id indexing and episode[step_id] cases.\n",
    "\n",
    "        Args:\n",
    "            taskvar: Task variable key\n",
    "            step_id: Step ID to access\n",
    "            episode: Optional episode number\n",
    "\n",
    "        Returns:\n",
    "            Target labels dictionary for the specified step\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # First try direct step_id indexing\n",
    "            return self.taskvar_gt_target_labels[taskvar][step_id]\n",
    "        except KeyError:\n",
    "            return self.taskvar_gt_target_labels[taskvar][episode][step_id]\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        taskvar,\n",
    "        step_id,\n",
    "        pcd_images,\n",
    "        sem_images,\n",
    "        gripper_pose,\n",
    "        arm_links_info,\n",
    "        rgb_images=None,\n",
    "        episode_id=None,\n",
    "    ):\n",
    "        episode = f\"episode{episode_id}\"\n",
    "        task, variation = taskvar.split(\"+\")\n",
    "        pcd_xyz = pcd_images.reshape(-1, 3)\n",
    "        pcd_sem = sem_images.reshape(-1)\n",
    "        if self.use_color:\n",
    "            assert rgb_images is not None\n",
    "            pcd_rgb = rgb_images.reshape(-1, 3)\n",
    "\n",
    "        # remove background and table points\n",
    "        fg_mask = get_pc_foreground_mask(pcd_xyz, self.workspace)\n",
    "        pcd_xyz = pcd_xyz[fg_mask]\n",
    "        pcd_sem = pcd_sem[fg_mask]\n",
    "        if self.use_color:\n",
    "            pcd_rgb = pcd_rgb[fg_mask]\n",
    "\n",
    "        pcd_xyz, idxs = voxelize_pcd(pcd_xyz, voxel_size=self.voxel_size)\n",
    "        pcd_sem = pcd_sem[idxs]\n",
    "        if self.use_color:\n",
    "            pcd_rgb = pcd_rgb[idxs]\n",
    "\n",
    "        if self.rm_robot != \"none\":\n",
    "            if self.rm_robot == \"box\":\n",
    "                robot_box = RobotBox(arm_links_info, keep_gripper=False)\n",
    "            elif self.rm_robot == \"box_keep_gripper\":\n",
    "                robot_box = RobotBox(arm_links_info, keep_gripper=True)\n",
    "            robot_point_idxs = robot_box.get_pc_overlap_ratio(\n",
    "                xyz=pcd_xyz, return_indices=True\n",
    "            )[1]\n",
    "            robot_point_idxs = np.array(list(robot_point_idxs))\n",
    "            if len(robot_point_idxs) > 0:\n",
    "                mask = np.ones((pcd_xyz.shape[0],), dtype=bool)\n",
    "                mask[robot_point_idxs] = False\n",
    "                pcd_xyz = pcd_xyz[mask]\n",
    "                pcd_sem = pcd_sem[mask]\n",
    "                if self.use_color:\n",
    "                    pcd_rgb = pcd_rgb[mask]\n",
    "\n",
    "        # sample points\n",
    "        if len(pcd_xyz) > self.num_points:\n",
    "            point_idxs = np.random.permutation(len(pcd_xyz))[: self.num_points]\n",
    "        else:\n",
    "            if self.same_npoints_per_example:\n",
    "                point_idxs = np.random.choice(\n",
    "                    pcd_xyz.shape[0], self.num_points, replace=True\n",
    "                )\n",
    "            else:\n",
    "                point_idxs = np.arange(pcd_xyz.shape[0])\n",
    "        pcd_xyz = pcd_xyz[point_idxs]\n",
    "        pcd_sem = pcd_sem[point_idxs]\n",
    "        height = pcd_xyz[..., 2] - self.TABLE_HEIGHT\n",
    "        if self.use_color:\n",
    "            pcd_rgb = pcd_rgb[point_idxs]\n",
    "\n",
    "        # robot pcd_label\n",
    "        pcd_label = np.zeros_like(pcd_sem)\n",
    "        robot_box = RobotBox(arm_links_info, keep_gripper=False)\n",
    "        robot_point_idxs = robot_box.get_pc_overlap_ratio(\n",
    "            xyz=pcd_xyz, return_indices=True\n",
    "        )[1]\n",
    "        robot_point_idxs = np.array(list(robot_point_idxs))\n",
    "        if len(robot_point_idxs) > 0:\n",
    "            pcd_label[robot_point_idxs] = 1\n",
    "        for query_key, query_label_id in zip([\"object\", \"target\"], [2, 3]):\n",
    "            target_labels = self.get_target_labels(taskvar, step_id, episode)\n",
    "            if target_labels is None or query_key not in target_labels:\n",
    "                continue\n",
    "\n",
    "            gt_target_labels = target_labels[query_key]\n",
    "\n",
    "            if self.pc_label_type != \"mix\":\n",
    "                pc_label_type = self.pc_label_type\n",
    "            else:\n",
    "                pc_label_type = random.choice([\"coarse\", \"fine\"])\n",
    "\n",
    "            labels = (\n",
    "                gt_target_labels[pc_label_type]\n",
    "                if pc_label_type in gt_target_labels\n",
    "                else gt_target_labels[\"fine\"]\n",
    "            )\n",
    "            gt_query_mask = [pcd_sem == x for x in labels]\n",
    "            gt_query_mask = np.sum(gt_query_mask, 0) > 0\n",
    "            if \"zrange\" in gt_target_labels:\n",
    "                gt_query_mask = (\n",
    "                    gt_query_mask\n",
    "                    & (pcd_xyz[..., 2] > gt_target_labels[\"zrange\"][0])\n",
    "                    & (pcd_xyz[..., 2] < gt_target_labels[\"zrange\"][1])\n",
    "                )\n",
    "            if \"xy_bbox\" in gt_target_labels and self.pc_label_type != \"coarse\":\n",
    "                bbox_offset = gt_target_labels[\"xy_bbox\"][\"bbox_offset\"]\n",
    "                bbox_size = gt_target_labels[\"xy_bbox\"][\"bbox_size\"]\n",
    "\n",
    "                obj_pose = gt_target_labels[\"xy_bbox\"][\"obj_pose\"]\n",
    "                bbox_pos = obj_pose[:3]\n",
    "                gripper_quat = obj_pose[3:]\n",
    "\n",
    "                bbox_rot = R.from_quat(gripper_quat).as_matrix()\n",
    "\n",
    "                # Rotate the offset by the rotation matrix\n",
    "                rotated_offset = bbox_rot @ bbox_offset\n",
    "\n",
    "                obbox = o3d.geometry.OrientedBoundingBox(bbox_pos, bbox_rot, bbox_size)\n",
    "                obbox.translate(rotated_offset, relative=True)\n",
    "\n",
    "                pcd = o3d.geometry.PointCloud()\n",
    "                pcd.points = o3d.utility.Vector3dVector(pcd_xyz)\n",
    "                box_idx = obbox.get_point_indices_within_bounding_box(pcd.points)\n",
    "\n",
    "                bbox_mask = np.zeros((pcd_xyz.shape[0],), dtype=bool)\n",
    "                if box_idx:  # If not empty\n",
    "                    indices = np.array(box_idx, dtype=np.int64)\n",
    "                    bbox_mask[indices] = True\n",
    "\n",
    "                gt_query_mask = gt_query_mask & bbox_mask\n",
    "            pcd_label[gt_query_mask] = query_label_id\n",
    "\n",
    "        # normalize point cloud\n",
    "        if self.xyz_shift == \"none\":\n",
    "            pc_centroid = np.zeros((3,))\n",
    "        elif self.xyz_shift == \"center\":\n",
    "            pc_centroid = np.mean(pcd_xyz, 0)\n",
    "        elif self.xyz_shift == \"gripper\":\n",
    "            pc_centroid = copy.deepcopy(gripper_pose[:3])\n",
    "        if self.xyz_norm:\n",
    "            pc_radius = np.max(np.sqrt(np.sum((pcd_xyz - pc_centroid) ** 2, axis=1)))\n",
    "        else:\n",
    "            pc_radius = 1\n",
    "        pcd_xyz = (pcd_xyz - pc_centroid) / pc_radius\n",
    "        gripper_pose[:3] = (gripper_pose[:3] - pc_centroid) / pc_radius\n",
    "\n",
    "        pcd_ft = pcd_xyz\n",
    "        if self.use_height:\n",
    "            pcd_ft = np.concatenate([pcd_ft, height[:, None]], -1)\n",
    "        if self.use_color:\n",
    "            pcd_rgb = (pcd_rgb / 255.0) * 2 - 1\n",
    "            pcd_ft = np.concatenate([pcd_ft, pcd_rgb], -1)\n",
    "\n",
    "        outs = {\n",
    "            \"pc_fts\": torch.from_numpy(pcd_ft).float(),\n",
    "            \"pc_labels\": torch.from_numpy(pcd_label).long(),\n",
    "            \"offset\": torch.LongTensor([pcd_xyz.shape[0]]),\n",
    "            \"npoints_in_batch\": [pcd_xyz.shape[0]],\n",
    "            \"pc_centroids\": pc_centroid,\n",
    "            \"pc_radius\": pc_radius,\n",
    "            \"ee_poses\": torch.from_numpy(gripper_pose).float().unsqueeze(0),\n",
    "        }\n",
    "\n",
    "        return outs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "59deffe1-a61a-492e-b777-7d949576f22e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "723bcb741e601b65",
   "metadata": {},
   "source": [
    "step = 3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a6cd0ecdda4c9167",
   "metadata": {},
   "source": [
    "obs_step = obs_dict[step]['obs']\n",
    "pcd_images = obs_step['pc']\n",
    "rgb_images = obs_step[\"rgb\"]\n",
    "sem_images = obs_step[\"gt_mask\"]\n",
    "arm_links_info = obs_step[\"arm_links_info\"]\n",
    "gripper_pose = copy.deepcopy(obs_step[\"gripper\"])\n",
    "gt_label_file = f\"../assets/{benchmark}/taskvars_target_label_zrange_{benchmark}.json\"\n",
    "\n",
    "vlm_pipeline = GroundtruthVision(\n",
    "        gt_label_file,\n",
    "        num_points=4096,\n",
    "        voxel_size=0.01,\n",
    "        same_npoints_per_example=False,\n",
    "        rm_robot=\"box_keep_gripper\",\n",
    "        xyz_shift=\"none\",\n",
    "        xyz_norm=False,\n",
    "        use_height=True,\n",
    "        pc_label_type=\"mix\",\n",
    "        use_color=False,\n",
    "    )\n",
    "\n",
    "batch = vlm_pipeline(\n",
    "        taskvar,\n",
    "        cache_list[step][\"highlevel_step_id_norelease\"],\n",
    "        pcd_images,\n",
    "        sem_images,\n",
    "        gripper_pose,\n",
    "        arm_links_info,\n",
    "        rgb_images=rgb_images,\n",
    "        episode_id=episode_id,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f717025bb6e1989",
   "metadata": {},
   "source": [
    "xyz = batch['pc_fts'][:, :3]\n",
    "labels = batch['pc_labels']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "185bab3536ab4d97",
   "metadata": {},
   "source": [
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{\"type\": \"image\"}, {\"type\": \"scene\"}]],\n",
    "    subplot_titles=[\"Front View\", \"Point Cloud\"]\n",
    ")\n",
    "\n",
    "front_view = obs_dict[step]['obs']['rgb'][-1]\n",
    "fig.add_trace(\n",
    "    go.Image(z=front_view),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "rgb = np.zeros((xyz.shape[0], 3))\n",
    "rgb[labels == 0] = [0.7, 0.7, 0.7]  # Light grey\n",
    "rgb[labels == 1] = [0.0, 0.0, 1.0]  # Blue\n",
    "rgb[labels == 2] = [1.0, 0.65, 0.0]  # Orange\n",
    "rgb[labels == 3] = [0.0, 1.0, 0.0]  # Green\n",
    "\n",
    "\n",
    "colors = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b in rgb]\n",
    "\n",
    "# Add point cloud\n",
    "fig.add_trace(\n",
    "    go.Scatter3d(\n",
    "        x=xyz[:, 0],\n",
    "        y=xyz[:, 1],\n",
    "        z=xyz[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=colors,\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    margin=dict(l=0, r=0, b=0, t=30),\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "# Update 3D scene settings\n",
    "scene_settings = dict(\n",
    "    aspectmode='data',\n",
    "    xaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True),\n",
    "    yaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True),\n",
    "    zaxis=dict(backgroundcolor='white', gridcolor='lightgrey', showbackground=True)\n",
    ")\n",
    "fig.update_scenes(scene_settings)\n",
    "\n",
    "fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f475787fcd04885",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
